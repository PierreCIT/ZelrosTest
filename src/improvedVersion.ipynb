{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zelros technical test : improved version (word embedding)\n",
    "## Word embedding using glove given in the competition data\n",
    "Import of necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version : 2.0.0\n",
      "Num GPUs available:  1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "dir_path = os.path.dirname(os.path.realpath(\"./src\"))\n",
    "sys.path.insert(0, dir_path)\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import tensorflow as tf\n",
    "from tqdm._tqdm_notebook import tqdm_notebook \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import re\n",
    "import heapq\n",
    "from sklearn import metrics\n",
    "from keras_tqdm_mod.tqdm_notebook_callback import TQDMNotebookCallback\n",
    "\n",
    "tqdm_notebook.pandas()\n",
    "Input = tf.keras.layers.Input\n",
    "Bidirectional = tf.keras.layers.Bidirectional\n",
    "CuDNNLSTM = tf.compat.v1.keras.layers.CuDNNLSTM\n",
    "Dense = tf.keras.layers.Dense\n",
    "Dropout = tf.keras.layers.Dropout\n",
    "GlobalMaxPool1D = tf.keras.layers.GlobalMaxPool1D\n",
    "\n",
    "print(\"Tensorflow version : {}\".format(tf.__version__))\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs available: \", len(gpus))\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global variables to use in this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "maxlen = 30 # maximum number of words to be used by question\n",
    "batch_size = 200 # Training batch size\n",
    "validation_batch_size = 200 # Validation batch size\n",
    "epochs = 2 # number of epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 30, 128)           187392    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 30, 128)           99328     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 288,801\n",
      "Trainable params: 288,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(Bidirectional(CuDNNLSTM(64, return_sequences = True), input_shape=(maxlen,300)))\n",
    "model.add(Bidirectional(CuDNNLSTM(64, return_sequences = True)))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the Glove pretrained data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3ece942909472d834bb68f0e1b21d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Reading Glove data', max=1, style=ProgressS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 2196016 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Source https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n",
    "embeddings_index = {}\n",
    "f = open(\"../dataset/embeddings/glove.840B.300d/glove.840B.300d.txt\", \"r\",  encoding=\"utf8\")\n",
    "for line in tqdm_notebook(f, desc=\"Reading Glove data\"):\n",
    "    values = line.split(\" \")\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype=\"float32\")\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1306122 training data available\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"../dataset/train.csv\")\n",
    "print(\"{} training data available\".format(data_df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove ponctuations and unnecessary spaces in sentences as well as transfer to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c98cba8b8843908bcec1f97c9d0f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1306122), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Check the result on the first sentence : How did Quebec nationalists see their province as a nation in the 1960s?\n"
     ]
    }
   ],
   "source": [
    "def rm_double_spaces(sentence):\n",
    "    sentence = re.sub(r'\\s+',' ',sentence) # Remove multiple space\n",
    "    if sentence[-1]==\" \": # Remove useless space at the end of the sentence\n",
    "        sentence = sentence[:-1]\n",
    "    return sentence\n",
    "\n",
    "data_df[\"question_text\"] = data_df[\"question_text\"].progress_apply(rm_double_spaces)\n",
    "print(\"Check the result on the first sentence : {}\".format(data_df[\"question_text\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset in train data and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(data_df, test_size=0.1)\n",
    "del data_df #no longer needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the data repartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 1175509, validation size: 130613, 11% of the training dataset size\n",
      "Percentage of positives in train = 0.06 and in val 0.06\n"
     ]
    }
   ],
   "source": [
    "percentage_in_train = train_df.groupby(\"target\").count()[\"qid\"][1]/train_df.shape[0]\n",
    "percentage_in_val = val_df.groupby(\"target\").count()[\"qid\"][1]/val_df.shape[0]\n",
    "print(f\"Train dataset size: {train_df.shape[0]}, validation size: {val_df.shape[0]}, \"\n",
    "      f\"{math.floor(val_df.shape[0]*100/train_df.shape[0])}% of the training dataset size\")\n",
    "print(\"Percentage of positives in train = {:.2f} and in val {:.2f}\".format(percentage_in_train,percentage_in_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ```Glove embedding``` from the train data (a word is a vector of 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Convert to embeddings\n",
    "def question_to_vect(question):\n",
    "    empty_emb = np.zeros(300)\n",
    "    words = question.split()[:maxlen]\n",
    "    embeds = [embeddings_index.get(x, empty_emb) for x in words] # Get the embedding if it exists otherwise empty_emb\n",
    "    embeds+= [empty_emb] * (maxlen - len(embeds)) # Fill the list of vectors with empty_emb if the question it shorter\n",
    "    return np.array(embeds, dtype=np.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a training generator to feed data to the network, and a validation data generator to check the progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def training_generator(_train_df):\n",
    "    nb_batches = _train_df.shape[0]//batch_size\n",
    "    while True:\n",
    "        _train_df = _train_df.sample(frac=1) # shuffle the data\n",
    "        for i in range(nb_batches):\n",
    "            questions = _train_df.iloc[i*batch_size:(i+1)*batch_size, 1]\n",
    "            vect_questions = np.asarray([question_to_vect(question) for question in questions])\n",
    "            yield (np.asarray(vect_questions), np.asarray(_train_df[\"target\"][i*batch_size:(i+1)*batch_size].values))\n",
    "\n",
    "def validation_generator(_val_df, predict=False):\n",
    "    nb_batches = _val_df.shape[0]//validation_batch_size\n",
    "    while True:\n",
    "        for i in range(nb_batches):\n",
    "            questions = _val_df.iloc[i*batch_size:(i+1)*batch_size, 1]\n",
    "            vect_questions = np.asarray([question_to_vect(question) for question in questions])\n",
    "            if not predict:\n",
    "                yield (np.asarray(vect_questions),np.asarray(_val_df[\"target\"][i*batch_size:(i+1)*batch_size].values))\n",
    "            else:\n",
    "                yield np.asarray(vect_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps per epoch = 5877, epochs = 2, batch_size = 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d727fb9e0e0c4dbeb8b38e94b8d8e7f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=2, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2807b03ffbe4cf493b9ea4936960dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=5877, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d1d6510c5745409ba152f738067cfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=5877, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24bfac42320>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = training_generator(train_df)\n",
    "\n",
    "print(\"steps per epoch = {}, epochs = {}, batch_size = {}\".format(train_df.shape[0] // batch_size, epochs, batch_size))\n",
    "model.fit_generator(generator, steps_per_epoch=train_df.shape[0] // batch_size, epochs=epochs, verbose=0,\n",
    "                   callbacks=[TQDMNotebookCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On the validation dataset the loss is 0.109 and accuracy is 0.958\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate_generator(validation_generator(val_df),val_df.shape[0]//validation_batch_size)\n",
    "print(\"On the validation dataset the loss is {:.3f} and accuracy is {:.3f}\".format(results[0], results[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the predictions for all validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictions_val = model.predict_generator(validation_generator(val_df, predict=True), \n",
    "                                          steps = val_df.shape[0]//validation_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the F1 score to compute the threshold for insincere questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at the threshold 0.01 is 0.35574196874194525\n",
      "F1 score at the threshold 0.02 is 0.43605919462295856\n",
      "F1 score at the threshold 0.03 is 0.4836002541041159\n",
      "F1 score at the threshold 0.04 is 0.5143624940988488\n",
      "F1 score at the threshold 0.05 is 0.537293831356947\n",
      "F1 score at the threshold 0.06 is 0.5561475576524179\n",
      "F1 score at the threshold 0.07 is 0.571392200958968\n",
      "F1 score at the threshold 0.08 is 0.5831172825943666\n",
      "F1 score at the threshold 0.09 is 0.5931834662799129\n",
      "F1 score at the threshold 0.1 is 0.6010338564709169\n",
      "F1 score at the threshold 0.11 is 0.6091399646626235\n",
      "F1 score at the threshold 0.12 is 0.6151144069863882\n",
      "F1 score at the threshold 0.13 is 0.6216162420382166\n",
      "F1 score at the threshold 0.14 is 0.6250760186499088\n",
      "F1 score at the threshold 0.15 is 0.628285743737759\n",
      "F1 score at the threshold 0.16 is 0.6298783046579941\n",
      "F1 score at the threshold 0.17 is 0.6333209173628479\n",
      "F1 score at the threshold 0.18 is 0.6374553716325868\n",
      "F1 score at the threshold 0.19 is 0.6410874808156106\n",
      "F1 score at the threshold 0.2 is 0.6433442368464822\n",
      "F1 score at the threshold 0.21 is 0.6438832772166106\n",
      "F1 score at the threshold 0.22 is 0.6448168134052825\n",
      "F1 score at the threshold 0.23 is 0.6459448569619524\n",
      "F1 score at the threshold 0.24 is 0.6457409568261376\n",
      "F1 score at the threshold 0.25 is 0.6462010744435918\n",
      "F1 score at the threshold 0.26 is 0.6474837323144887\n",
      "F1 score at the threshold 0.27 is 0.6472648230889989\n",
      "F1 score at the threshold 0.28 is 0.6465633011842267\n",
      "F1 score at the threshold 0.29 is 0.647422425516133\n",
      "F1 score at the threshold 0.3 is 0.6457057132141517\n",
      "F1 score at the threshold 0.31 is 0.6434035021177066\n",
      "F1 score at the threshold 0.32 is 0.6435371541754521\n",
      "F1 score at the threshold 0.33 is 0.6427140549273022\n",
      "F1 score at the threshold 0.34 is 0.6389016018306636\n",
      "F1 score at the threshold 0.35 is 0.635306553911205\n",
      "F1 score at the threshold 0.36 is 0.632760809997995\n",
      "F1 score at the threshold 0.37 is 0.630933117583603\n",
      "F1 score at the threshold 0.38 is 0.6288126361655774\n",
      "F1 score at the threshold 0.39 is 0.6252747252747253\n",
      "F1 score at the threshold 0.4 is 0.6212257930172833\n",
      "F1 score at the threshold 0.41 is 0.6173913043478261\n",
      "F1 score at the threshold 0.42 is 0.6149270641552187\n",
      "F1 score at the threshold 0.43 is 0.611504108610218\n",
      "F1 score at the threshold 0.44 is 0.608526293010171\n",
      "F1 score at the threshold 0.45 is 0.6045222465353757\n",
      "F1 score at the threshold 0.46 is 0.6001473839351511\n",
      "F1 score at the threshold 0.47 is 0.5938942665673865\n",
      "F1 score at the threshold 0.48 is 0.5875808149150502\n",
      "F1 score at the threshold 0.49 is 0.5805081532043989\n",
      "F1 score at the threshold 0.5 is 0.5750612745098039\n",
      "\n",
      "Best results for a threshold of 0.26 with F1 score of 0.6474837323144887\n"
     ]
    }
   ],
   "source": [
    "_max=0\n",
    "threshold = 0\n",
    "for thresh_test in np.arange(0.01, 0.51, 0.01):\n",
    "    thresh_test = np.round(thresh_test,2)\n",
    "    F1_score = metrics.f1_score(val_df.iloc[:(val_df.shape[0]//validation_batch_size)*validation_batch_size, 2],\n",
    "                                (predictions_val>thresh_test).astype(int))\n",
    "    if F1_score>_max: _max,threshold = F1_score, thresh_test\n",
    "    print(\"F1 score at the threshold {} is {}\".format(thresh_test,F1_score))\n",
    "\n",
    "print(\"\\nBest results for a threshold of {} with F1 score of {}\".format(threshold, _max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
